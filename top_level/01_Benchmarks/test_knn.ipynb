{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml import command, Input, Output\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azureml.core import Workspace, Dataset, Datastore\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# GLOBAL FUNCTIONS\n",
    "import sys\n",
    "sys.path.append(\"../../../\")\n",
    "from utils.data_processing import add_day_ahead_column\n",
    "from utils.error_metrics import _calc_mae, _calc_mse, _calc_rmse, _calc_nrmse, _calc_mape, _calc_mase, _calc_msse, _seas_naive_fcst, _calc_metrics\n",
    "\n",
    "\n",
    "#PLOTTING\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set global parameters\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.size'] = 12  # Font size\n",
    "stanford_colors = ['#8C1515', '#175E54', '#279989', '#8F993E', '#6FA287', '#4298B5', \n",
    "                   '#007C92', '#E98300', '#E04F39', '#FEDD5C', '#620059', '#651C32', \n",
    "                   '#5D4B3C', '#7F7776', '#DAD7CB']\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=stanford_colors)\n",
    "\n",
    "# authenticate\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "# Get a handle to the workspace\n",
    "from config import subscription_id, resource_group, workspace_name\n",
    "\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id = subscription_id,\n",
    "    resource_group_name = resource_group,\n",
    "    workspace_name = workspace_name\n",
    ")\n",
    "\n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
    "datastore = Datastore.get(workspace, \"workspaceblobstore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test notebook for KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data - NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to input file\n",
    "data_path= \"azureml://subscriptions/orkspaceblobstore/paths/LocalUpload/00_load_country.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate the input data\n",
    "short_path = 'LocalUpload' + data_path.split('LocalUpload')[1] \n",
    "dataset = Dataset.Tabular.from_delimited_files(path=(datastore, short_path))\n",
    "df = dataset.to_pandas_dataframe()\n",
    "\n",
    "df['ds'] = pd.to_datetime(df['ds'])\n",
    "df['y'] = pd.to_numeric(df['y'], errors='coerce')\n",
    "df = df.rename(columns={'country': 'ID'})\n",
    "df['temp'] = pd.to_numeric(df['temp'], errors='coerce')\n",
    "\n",
    "df = df[['ds', 'ID', 'temp', 'y']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Implement kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "k = 3 # use the 3 most similar days\n",
    "n = 24 # go 24 hours back\n",
    "n_temp = 33 # go 33 hours back\n",
    "cut_off = 14 # forecast the next day at 2pm\n",
    "train_test_split = pd.to_datetime('2014-01-01 00:00:00')\n",
    "IDs = df['ID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Feature Vector Formation\n",
    "Training Data: For each day in the training data, create a feature vector that includes the temperature forecast from  pm and the 'y' value from 24 hours before.\n",
    "Testing Data: For each day in the testing data (2021), also create a feature vector using the same criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form feature vectors\n",
    "def form_feature_vectors(df):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    min_day = df['ds'].min().date()\n",
    "    max_day = df['ds'].max().date()\n",
    "    skipped_days=[]\n",
    "\n",
    "    for date in pd.date_range(start = min_day, end=max_day, freq='D'):\n",
    "        log = True if date == min_day else False\n",
    "        \n",
    "        # get the slices for y and temp in the corresponding length (n and n_temp before the cut_off)\n",
    "        X_slice_value = df[df['ds'] < pd.to_datetime(str(date) + ' 14:00:00')].tail(n)['y'].values\n",
    "        X_slice_temp = df[df['ds'] < pd.to_datetime(str(date) + ' 14:00:00')].tail(n_temp)['temp'].values\n",
    "\n",
    "        # get the values for the next day (midnight to midnight) --> plus one day\n",
    "\n",
    "        y_slice_value = df[(df['ds'] >= pd.to_datetime(str(date + pd.Timedelta(days=1)) + ' 00:00:00')) &\n",
    "                            (df['ds'] <= pd.to_datetime(str(date + pd.Timedelta(days=1)) + ' 23:00:00'))]['y'].values\n",
    "\n",
    "        if log:\n",
    "            print('X_slice_value', X_slice_value)\n",
    "            print('X_slice_temp', X_slice_temp)\n",
    "            print('y_slice_value', y_slice_value)\n",
    "\n",
    "        # if the length of the slices is not equal to n or n_temp, skip this day\n",
    "        if len(X_slice_value) != n or len(X_slice_temp) != n_temp or len(y_slice_value) != 24:\n",
    "            skipped_days.append(date)\n",
    "            continue\n",
    "\n",
    "        # append the slices to the feature vectors\n",
    "        X.append(np.append(X_slice_value, X_slice_temp))\n",
    "        y.append(y_slice_value)\n",
    "    \n",
    "    print(skipped_days)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Initialize an empty list to store results\n",
    "result_list = []\n",
    "\n",
    "for id in IDs:\n",
    "    print('ID', id)\n",
    "    df_id = df[df['ID'] == id]\n",
    "    # for every ID split in train and test set\n",
    "    df_train, df_test = df_id[df_id['ds'] < train_test_split], df_id[df_id['ds'] >= train_test_split]\n",
    "\n",
    "    X_train, y_train = form_feature_vectors(df_train)\n",
    "    X_test, y_test = form_feature_vectors(df_test)\n",
    "\n",
    "    knn = KNeighborsRegressor(n_neighbors=3)\n",
    "\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    y_pred_full = np.concatenate((np.full(24, np.nan), y_pred.flatten(), np.full(24, np.nan)))\n",
    "    df_test['y_pred'] = y_pred_full.flatten()\n",
    "    \n",
    "    # Append the test dataframe with predictions to the result list\n",
    "    result_list.append(df_test)\n",
    "\n",
    "# Concatenate the list of dataframes into a single dataframe\n",
    "df_result = pd.concat(result_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "df_result = pd.DataFrame()\n",
    "\n",
    "for id in IDs:\n",
    "    print('ID', id)\n",
    "    df_id = df[df['ID'] == id]\n",
    "    # for every ID split in train and test set\n",
    "    df_train, df_test = df_id[df_id['ds'] < train_test_split], df_id[df_id['ds'] >= train_test_split]\n",
    "\n",
    "    X_train, y_train = form_feature_vectors(df_train)\n",
    "    X_test, y_test = form_feature_vectors(df_test)\n",
    "\n",
    "    knn = KNeighborsRegressor(n_neighbors=3)\n",
    "\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    y_pred_full = np.concatenate((np.full(24, np.nan), y_pred.flatten(), np.full(24, np.nan)))\n",
    "    df_test['y_pred'] = y_pred_full.flatten()\n",
    "    \n",
    "    df_result = df_result.append(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('result_knn.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add snaive for every ID by shifting\n",
    "df_result['snaive'] = df_result.groupby('ID')['y'].shift(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(columns=['ID', 'RMSE', 'MAE', 'MAPE', 'MASE', 'MSSE'])\n",
    "\n",
    "for id in IDs:\n",
    "    df_id = df_result[df_result['ID'] == id]\n",
    "    rmse = _calc_rmse(predictions=df_id['y_pred'], truth=df_id['y'])\n",
    "    mae = _calc_mae(predictions=df_id['y_pred'], truth=df_id['y'])\n",
    "    mape = _calc_mape(predictions=df_id['y_pred'], truth=df_id['y'])\n",
    "    mase = _calc_mase(predictions=df_id['y_pred'], truth=df_id['y'], snaive_predictions=df_id['snaive'])\n",
    "    msse = _calc_msse(predictions=df_id['y_pred'], truth=df_id['y'], snaive_predictions=df_id['snaive'])\n",
    "    metrics = pd.concat([metrics, pd.DataFrame({'ID': id, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'MASE': mase, 'MSSE': msse}, index=[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.to_csv('metrics_knn.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
