{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "sys.path.append(\"../../../\")\n",
    "from utils.data_processing import add_day_ahead_column\n",
    "from utils.error_metrics import _calc_mae, _calc_mse, _calc_rmse, _calc_nrmse, _calc_mape, _calc_mase, _calc_msse, _seas_naive_fcst, _calc_metrics\n",
    "\n",
    "### Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.size'] = 12  # Font size\n",
    "stanford_colors = ['#8C1515', '#175E54', '#279989', '#8F993E', '#6FA287', '#4298B5', \n",
    "                   '#007C92', '#E98300', '#E04F39', '#FEDD5C', '#620059', '#651C32', \n",
    "                   '#5D4B3C', '#7F7776', '#DAD7CB']\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=stanford_colors)\n",
    "\n",
    "### ML AZURE\n",
    "from azureml.core import Workspace, Dataset, Datastore\n",
    "import mlflow\n",
    "from config import subscription_id, resource_group, workspace_name\n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
    "datastore = Datastore.get(workspace, \"workspaceblobstore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load original data\n",
    "\n",
    "df = pd.read_csv('../00_load_country.csv')\n",
    "df = df.drop(columns=['temp', 'humidity', 'precipitation', 'cloud', 'wind'])\n",
    "df['ds'] = pd.to_datetime(df['ds'])\n",
    "df = df.rename(columns={'country': 'ID'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load xgboost results\n",
    "\n",
    "name = 'funny_match_827'\n",
    "path = f'azureml/{name}/results/'\n",
    "\n",
    "file = 'forecasts_forecast_test.csv'\n",
    "dataset = Dataset.Tabular.from_delimited_files(path=(datastore, path + file))\n",
    "forecast_test = dataset.to_pandas_dataframe()\n",
    "forecast_test['ds'] = pd.to_datetime(forecast_test['ds'])\n",
    "\n",
    "forecast_xgboost = df.merge(forecast_test, on=['ds', 'ID'], how='left')\n",
    "forecast_xgboost.rename(columns={'yhat': 'yhat_xgboost'}, inplace=True)\n",
    "forecast_xgboost = forecast_xgboost[forecast_xgboost['ds'] >= '2014-01-01'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prototype Plot\n",
    "\n",
    "import plotly.express as px\n",
    "df_id = forecast_xgboost[forecast_xgboost['ID']=='ALB']\n",
    "fig = px.line(df_id, x='ds', y=['y', 'yhat_xgboost'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Error metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Error metrics\n",
    "\n",
    "forecast_xgboost['snaive'] = forecast_xgboost.groupby('ID')['y'].shift(48)\n",
    "metrics = pd.DataFrame()\n",
    "\n",
    "for ID in forecast_xgboost['ID'].unique():\n",
    "    df_id = forecast_xgboost[forecast_xgboost['ID'] == ID]\n",
    "    rmse = _calc_rmse(predictions=df_id['yhat_xgboost'], truth=df_id['y'])\n",
    "    mae = _calc_mae(predictions=df_id['yhat_xgboost'], truth=df_id['y'])\n",
    "    mape = _calc_mape(predictions=df_id['yhat_xgboost'], truth=df_id['y'])\n",
    "    mase = _calc_mase(predictions=df_id['yhat_xgboost'], truth=df_id['y'], snaive_predictions=df_id['snaive'])\n",
    "    msse = _calc_msse(predictions=df_id['yhat_xgboost'], truth=df_id['y'], snaive_predictions=df_id['snaive'])\n",
    "    new_row = {'ID':ID, 'RMSE':rmse, 'MAE':mae, 'MAPE':mape, 'MASE':mase, 'MSSE':msse}\n",
    "    metrics = pd.concat([metrics, pd.DataFrame([new_row])])\n",
    "\n",
    "metrics.to_csv('metrics_xgboost.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load arima results\n",
    "\n",
    "IDs = df['ID'].unique()\n",
    "print(IDs[:8])\n",
    "print(IDs[8:])\n",
    "job_names1 = [f'arima_{ID}_1625' for ID in IDs[:8]]\n",
    "job_names2 = [f'arima_{ID}_1626' for ID in IDs[8:]]\n",
    "job_names = job_names1 + job_names2\n",
    "forecast_arima = pd.DataFrame()\n",
    "\n",
    "for name in job_names:\n",
    "    path = f'azureml/{name}/results/'\n",
    "    file = 'forecasts_forecast_test.csv'\n",
    "    dataset = Dataset.Tabular.from_delimited_files(path=(datastore, path + file))\n",
    "    forecast_test = dataset.to_pandas_dataframe()\n",
    "    forecast_test['ds'] = pd.to_datetime(forecast_test['ds'])\n",
    "    forecast_arima = pd.concat([forecast_arima, forecast_test])\n",
    "\n",
    "forecast_arima = forecast_arima.merge(df[['ID', 'ds', 'y']], on=['ID', 'ds'], how='left')\n",
    "forecast_arima.rename(columns={'yhat': 'yhat_arima'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Error metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Error metrics\n",
    " \n",
    "forecast_arima['snaive'] = forecast_arima.groupby('ID')['y'].shift(48)\n",
    "metrics_arima = pd.DataFrame()\n",
    "\n",
    "for ID in forecast_arima['ID'].unique():\n",
    "    df_id = forecast_arima[forecast_arima['ID'] == ID]\n",
    "    rmse = _calc_rmse(predictions=df_id['yhat_arima'], truth=df_id['y'])\n",
    "    mae = _calc_mae(predictions=df_id['yhat_arima'], truth=df_id['y'])\n",
    "    mape = _calc_mape(predictions=df_id['yhat_arima'], truth=df_id['y'])\n",
    "    mase = _calc_mase(predictions=df_id['yhat_arima'], truth=df_id['y'], snaive_predictions=df_id['snaive'])\n",
    "    msse = _calc_msse(predictions=df_id['yhat_arima'], truth=df_id['y'], snaive_predictions=df_id['snaive'])\n",
    "    new_row = {'ID':ID, 'RMSE':rmse, 'MAE':mae, 'MAPE':mape, 'MASE':mase, 'MSSE':msse}\n",
    "    metrics_arima = pd.concat([metrics_arima, pd.DataFrame([new_row])])\n",
    "\n",
    "metrics_arima.to_csv('metrics_arima.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_knn = pd.read_csv('result_knn.csv', parse_dates=['ds'])\n",
    "forecast_knn.rename(columns={'y_pred': 'yhat_knn'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Seasonal Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Error metrics\n",
    "\n",
    "forecast_snaive = df.copy()\n",
    "forecast_snaive['yhat_snaive'] = forecast_snaive.groupby('ID')['y'].shift(48)\n",
    "metrics_snaive = pd.DataFrame()\n",
    "\n",
    "for id in df['ID'].unique():\n",
    "    df_id = forecast_snaive[forecast_snaive['ID'] == id]\n",
    "    df_id = df_id[df_id['ds'] >= '2021-01-01']\n",
    "    rmse = _calc_rmse(predictions=df_id['yhat_snaive'], truth=df_id['y'])\n",
    "    mae = _calc_mae(predictions=df_id['yhat_snaive'], truth=df_id['y'])\n",
    "    mape = _calc_mape(predictions=df_id['yhat_snaive'], truth=df_id['y'])\n",
    "    mase = _calc_mase(predictions=df_id['yhat_snaive'], truth=df_id['y'], snaive_predictions=df_id['yhat_snaive'])\n",
    "    msse = _calc_msse(predictions=df_id['yhat_snaive'], truth=df_id['y'], snaive_predictions=df_id['yhat_snaive'])\n",
    "    new_row = {'ID':id, 'RMSE':rmse, 'MAE':mae, 'MAPE':mape, 'MASE':mase, 'MSSE':msse}\n",
    "    metrics_snaive = pd.concat([metrics_snaive, pd.DataFrame([new_row])])\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "metrics_snaive.to_csv('metrics_snaive.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. NBeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load results\n",
    "\n",
    "name = 'amusing_monkey_wcg1zy2'\n",
    "path = f'azureml/{name}/results/'\n",
    "file = 'forecasts_forecast_test.csv'\n",
    "dataset = Dataset.Tabular.from_delimited_files(path=(datastore, path + file))\n",
    "forecast_test = dataset.to_pandas_dataframe()\n",
    "forecast_test['ds'] = pd.to_datetime(forecast_test['ds'])\n",
    "\n",
    "forecast_nbeats = df.merge(forecast_test, on=['ds', 'ID'], how='left')\n",
    "forecast_nbeats.rename(columns={'yhat': 'yhat_nbeats'}, inplace=True)\n",
    "forecast_nbeats = forecast_nbeats[forecast_nbeats['ds'] >= '2014-01-02'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Error metrics\n",
    "\n",
    "forecast_nbeats['snaive'] = forecast_nbeats.groupby('ID')['y'].shift(48)\n",
    "metrics = pd.DataFrame()\n",
    "\n",
    "for ID in forecast_nbeats['ID'].unique():\n",
    "    df_id = forecast_nbeats[forecast_nbeats['ID'] == ID]\n",
    "    rmse = _calc_rmse(predictions=df_id['yhat_nbeats'], truth=df_id['y'])\n",
    "    mae = _calc_mae(predictions=df_id['yhat_nbeats'], truth=df_id['y'])\n",
    "    mape = _calc_mape(predictions=df_id['yhat_nbeats'], truth=df_id['y'])\n",
    "    mase = _calc_mase(predictions=df_id['yhat_nbeats'], truth=df_id['y'], snaive_predictions=df_id['snaive'])\n",
    "    msse = _calc_msse(predictions=df_id['yhat_nbeats'], truth=df_id['y'], snaive_predictions=df_id['snaive'])\n",
    "    new_row = {'ID':ID, 'RMSE':rmse, 'MAE':mae, 'MAPE':mape, 'MASE':mase, 'MSSE':msse}\n",
    "    metrics = pd.concat([metrics, pd.DataFrame([new_row])])\n",
    "\n",
    "metrics.to_csv('metrics_nbeats.csv', index=False)\n",
    "metrics[['RMSE', 'MAE', 'MAPE', 'MASE', 'MSSE']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. TFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load results\n",
    "\n",
    "name = 'tidy_atemoya_fpsfw8r'\n",
    "path = f'azureml/{name}/results/'\n",
    "file = 'forecasts_forecast_test.csv'\n",
    "dataset = Dataset.Tabular.from_delimited_files(path=(datastore, path + file))\n",
    "forecast_test = dataset.to_pandas_dataframe()\n",
    "forecast_test['ds'] = pd.to_datetime(forecast_test['ds'])\n",
    "\n",
    "forecast_tft = df.merge(forecast_test, on=['ds', 'ID'], how='left')\n",
    "forecast_tft.rename(columns={'yhat': 'yhat_tft'}, inplace=True)\n",
    "forecast_tft = forecast_tft[forecast_tft['ds'] >= '2014-01-02'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Error metrics\n",
    "\n",
    "forecast_tft['snaive'] = forecast_tft.groupby('ID')['y'].shift(48)\n",
    "metrics = pd.DataFrame()\n",
    "\n",
    "for ID in forecast_tft['ID'].unique():\n",
    "    df_id = forecast_tft[forecast_tft['ID'] == ID]\n",
    "    rmse = _calc_rmse(predictions=df_id['yhat_tft'], truth=df_id['y'])\n",
    "    mae = _calc_mae(predictions=df_id['yhat_tft'], truth=df_id['y'])\n",
    "    mape = _calc_mape(predictions=df_id['yhat_tft'], truth=df_id['y'])\n",
    "    mase = _calc_mase(predictions=df_id['yhat_tft'], truth=df_id['y'], snaive_predictions=df_id['snaive'])\n",
    "    msse = _calc_msse(predictions=df_id['yhat_tft'], truth=df_id['y'], snaive_predictions=df_id['snaive'])\n",
    "    new_row = {'ID':ID, 'RMSE':rmse, 'MAE':mae, 'MAPE':mape, 'MASE':mase, 'MSSE':msse}\n",
    "    metrics = pd.concat([metrics, pd.DataFrame([new_row])])\n",
    "\n",
    "metrics.to_csv('metrics_tft.csv', index=False)\n",
    "metrics[['RMSE', 'MAE', 'MAPE', 'MASE', 'MSSE']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 99. Merge all  together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benchmarks = forecast_xgboost.merge(forecast_arima[['ID', 'ds', 'yhat_arima']], on=['ID', 'ds'], how='left')\n",
    "df_benchmarks = df_benchmarks.merge(forecast_knn[['ID', 'ds', 'yhat_knn']], on=['ID', 'ds'], how='left')\n",
    "df_benchmarks = df_benchmarks.merge(forecast_snaive[['ID', 'ds', 'yhat_snaive']], on=['ID', 'ds'], how='left')\n",
    "df_benchmarks = df_benchmarks.merge(forecast_nbeats[['ID', 'ds', 'yhat_nbeats']], on=['ID', 'ds'], how='left')\n",
    "df_benchmarks = df_benchmarks.merge(forecast_tft[['ID', 'ds', 'yhat_tft']], on=['ID', 'ds'], how='left')\n",
    "df_benchmarks.to_csv('../../../07_data/result_benchmarks_v2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
